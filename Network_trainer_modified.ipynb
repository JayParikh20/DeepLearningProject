{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network_trainer_modified.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Upload DATA_1 zip folder to files \n",
        "### Run following commands to train the network"
      ],
      "metadata": {
        "id": "6fydWCwswf8S"
      }
    },
    {
      "metadata": {
        "id": "RG3D4NzMwRdb"
      },
      "cell_type": "code",
      "source": [
        "# ! git clone https://github.com/amansharmaps3/LATEST3\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import ntpath\n",
        "import random"
      ],
      "metadata": {
        "id": "QGp4Ts5OwEOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EtGZh2zQwe12"
      }
    },
    {
      "metadata": {
        "id": "pbih_mdT2DI0"
      },
      "cell_type": "code",
      "source": [
        "datadir = 'DATA_1'\n",
        "class CarDataPreprocessor:\n",
        " \n",
        "    def __init__(self):\n",
        "      data_cols = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']\n",
        "      self.data = pd.read_csv(os.path.join(datadir, 'driving_log.csv'), names = data_cols)\n",
        "      # self.data = pd.read_csv('driving_log.csv', names = data_cols)\n",
        "      pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "      self.data['center'] = self.data['center'].apply(self.path_node)\n",
        "      self.data['left'] = self.data['left'].apply(self.path_node)\n",
        "      self.data['right'] = self.data['right'].apply(self.path_node)\n",
        "\n",
        "      self.bins_count = 25\n",
        "      self.samples = 400\n",
        "      self.center = 0\n",
        "      self.bins = 0\n",
        "\n",
        "    def path_node(self, path):\n",
        "      head, tail = ntpath.split(path)\n",
        "      return tail\n",
        "\n",
        "    def display_total_data(self):\n",
        "      hist, self.bins = np.histogram(self.data['steering'], self.bins_count)\n",
        "      self.center = (self.bins[:-1]+ self.bins[1:]) * 0.5\n",
        "      plt.bar(self.center, hist, width=0.05)\n",
        "      plt.plot((np.min(self.data['steering']), np.max(self.data['steering'])), (self.samples, self.samples))\n",
        "      print('total data:', len(self.data))\n",
        "\n",
        "    def drop_outlier_data(self):\n",
        "      remove_list = []\n",
        "      for j in range(self.bins_count):\n",
        "        list_ = []\n",
        "        for i in range(len(self.data['steering'])):\n",
        "          if self.data['steering'][i] >= self.bins[j] and self.data['steering'][i] <= self.bins[j+1]:\n",
        "            list_.append(i)\n",
        "        list_ = shuffle(list_)\n",
        "        list_ = list_[self.samples:]\n",
        "        remove_list.extend(list_)\n",
        "      self.data.drop(self.data.index[remove_list], inplace=True)\n",
        "\n",
        "      hist, _ = np.histogram(self.data['steering'], (self.bins_count))\n",
        "      plt.bar(self.center, hist, width=0.05)\n",
        "      plt.plot((np.min(self.data['steering']), np.max(self.data['steering'])), (self.samples, self.samples))\n",
        "    \n",
        "    def load_images_and_steering(self, datadir):\n",
        "      image_path = []\n",
        "      steering = []\n",
        "      for i in range(len(self.data)):\n",
        "        indexed_data = self.data.iloc[i]\n",
        "        center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]\n",
        "        image_path.append(os.path.join(datadir, center.strip()))\n",
        "        steering.append(float(indexed_data[3]))\n",
        "        image_path.append(os.path.join(datadir,left.strip()))\n",
        "        steering.append(float(indexed_data[3])+0.15)\n",
        "        image_path.append(os.path.join(datadir,right.strip()))\n",
        "        steering.append(float(indexed_data[3])-0.15)\n",
        "      image_paths = np.asarray(image_path)\n",
        "      steerings = np.asarray(steering)\n",
        "      return image_paths, steerings\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3UgEIGa2HsF"
      },
      "cell_type": "code",
      "source": [
        "cdp = CarDataPreprocessor()\n",
        "cdp.display_total_data()\n",
        "cdp.drop_outlier_data()\n",
        "image_paths, steerings = cdp.load_images_and_steering(datadir + '/IMG')\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(image_paths, steerings, test_size=0.2, random_state=6)\n",
        "\n",
        "print('Training Samples: {}\\nValid Samples: {}'.format(len(X_train), len(X_valid)))\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].hist(y_train, bins=cdp.bins_count, width=0.05, color='blue')\n",
        "axes[0].set_title('Training set')\n",
        "axes[1].hist(y_valid, bins=cdp.bins_count, width=0.05, color='red')\n",
        "axes[1].set_title('Validation set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8VLsrym2MzT"
      },
      "cell_type": "code",
      "source": [
        "class ImagePreprocessor:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def zoom(self, image):\n",
        "    zoom = iaa.Affine(scale=(1, 1.3))\n",
        "    image = zoom.augment_image(image)\n",
        "    return image\n",
        "\n",
        "  def pan(self, image):\n",
        "    pan = iaa.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "    image = pan.augment_image(image)\n",
        "    return image\n",
        "\n",
        "  def img_random_brightness(self, image):\n",
        "    brightness = iaa.Multiply((0.2, 1.2))\n",
        "    image = brightness.augment_image(image)\n",
        "    return image\n",
        "\n",
        "  def img_random_flip(self, image, steering_angle):\n",
        "    image = cv2.flip(image,1)\n",
        "    steering_angle = -steering_angle\n",
        "    return image, steering_angle\n",
        "\n",
        "  def random_augment(self, image, steering_angle):\n",
        "    image = mpimg.imread(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = self.pan(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = self.zoom(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = self.img_random_brightness(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image, steering_angle = self.img_random_flip(image, steering_angle)\n",
        "    \n",
        "    return image, steering_angle\n",
        "\n",
        "  def image_preprocess(self, image):\n",
        "    image = image[60:135,:,:]\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "    image = cv2.GaussianBlur(image,  (3, 3), 0)\n",
        "    image = cv2.resize(image, (200, 66))\n",
        "    image = image/255\n",
        "    return image\n",
        "\n",
        "  def display_preprocessed(original_image, preprocessed_image):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    fig.tight_layout()\n",
        "    axes[0].imshow(original_image)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[1].imshow(preprocessed_image)\n",
        "    axes[1].set_title('Preprocessed Image')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BcAbUfZj4TzD"
      },
      "cell_type": "code",
      "source": [
        "image_precessor = ImagePreprocessor()\n",
        "\n",
        "def batch_data(image_paths, steering_angle, batch_size, is_training):\n",
        "  while True:\n",
        "    image_batch = []\n",
        "    steering_batch = []\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      random_index = random.randint(0, len(image_paths) - 1)\n",
        "      \n",
        "      if is_training:\n",
        "        img, steering = image_precessor.random_augment(image_paths[random_index], steering_angle[random_index])\n",
        "     \n",
        "      else:\n",
        "        img = mpimg.imread(image_paths[random_index])\n",
        "        steering = steering_angle[random_index]\n",
        "      \n",
        "      img = image_precessor.image_preprocess(img)\n",
        "      image_batch.append(img)\n",
        "      steering_batch.append(steering)\n",
        "    yield (np.asarray(image_batch), np.asarray(steering_batch))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAoXWIC-4YjU"
      },
      "cell_type": "code",
      "source": [
        "x_train_gen, y_train_gen = next(batch_data(X_train, y_train, 1, 1))\n",
        "x_valid_gen, y_valid_gen = next(batch_data(X_valid, y_valid, 1, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBxMuYR14dSB"
      },
      "cell_type": "code",
      "source": [
        "def nvidia_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(24, (5, 5) , strides=(2,2), padding='same', input_shape=(66, 200, 3), activation='elu'))\n",
        "  model.add(Conv2D(36, (5, 5) , strides=(2,2), padding='same', activation='elu'))\n",
        "  model.add(Conv2D(48, (5, 5) , strides=(2,2), padding='same', activation='elu'))\n",
        "  model.add(Conv2D(64, 3, 3, padding='same', activation='elu'))\n",
        "  \n",
        "  model.add(Conv2D(64, 3, 3, padding='same', activation='elu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(100, activation = 'elu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(50, activation = 'elu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(10, activation = 'elu'))\n",
        "  model.add(Dropout(0.5))\n",
        " \n",
        "  model.add(Dense(1))\n",
        "  \n",
        "  optimizer = Adam(lr=1e-3)\n",
        "  model.compile(loss='mse', optimizer=optimizer)\n",
        "  return model\n",
        "model = nvidia_model()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gZYAc0u4hfD"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(batch_data(X_train, y_train, 100, 1),\n",
        "                                  steps_per_epoch=300, \n",
        "                                  epochs=50,\n",
        "                                  validation_data=batch_data(X_valid, y_valid, 100, 0),\n",
        "                                  validation_steps=200,\n",
        "                                  verbose=1,\n",
        "                                  shuffle = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuY7n0raEiTc"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "model.save('DATA_1.h5')\n",
        "from google.colab import files\n",
        "files.download('DATA_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}